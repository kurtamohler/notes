{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b17a65e",
   "metadata": {},
   "source": [
    "I'm interested in understanding [`torch.linalg.lu_solve`](https://docs.pytorch.org/docs/stable/generated/torch.linalg.lu_solve.html) with the aim of adding support for MPS.\n",
    "\n",
    "The purpose of `lu_solve` is to solve a matrix equation $A X = B$ for $X$, given $A$ and $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567da748",
   "metadata": {},
   "source": [
    "`lu_solve` relies on a strategy called LU decomposition. To paraphrase the [Wikipedia article](https://en.wikipedia.org/wiki/LU_decomposition) on LU decomposition, $A$ is separated into two matrices $L$, a lower triangular matrix, and $U$, an upper triangular matrix. Often, $A = LU$, though sometimes $A$ must be reordered to prevent division by zero or to control errors, in which case $P A Q = L U$, where $P$ and $Q$ are permutation matrices that reorder the rows and columns of $A$, respectively. However, it is usually sufficient to just use row permutations, $P A = L U$. This strategy is called \"LU factorization with partial pivoting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce08b3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In PyTorch, however, $A = P L U$, by defintion. So $P$ is actually the inverse of the $P$ matrix that the Wikipedia article mentions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188042c4",
   "metadata": {},
   "source": [
    "[`torch.linalg.lu`](https://docs.pytorch.org/docs/stable/generated/torch.linalg.lu.html) can be used to compute the matrices $P$, $L$, and $U$ given $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7682cfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "However it is not actually necessary to compute $L$ and $U$ separately in order to solve $A X = B$. So [`torch.linalg.lu_factor`](https://docs.pytorch.org/docs/stable/generated/torch.linalg.lu_factor.html) computes $LU$ and a `pivots` tensor. `pivots` is just a compactified representation of the $P$ matrix. $P$ is just the identity matrix with reordered rows, so it is mostly filled with zeros, wasting a lot of space. `pivots` is a vector where each element specifies a row index of the identity matrix. It's very easy to generate $P$ from `pivots`--you just take the identity matrix and swap the rows to the order that `pivots` indicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa83262",
   "metadata": {},
   "source": [
    "Since $A = P L U$, then $A X = B$ becomes $P L U X = B$, and solving for $X$, we get $X = U^{-1} L^{-1} P^{-1} B$. Since $P$ is a permutation matrix, its inverse is just its transpose, $P^{-1} = P^T$, so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2104d33",
   "metadata": {},
   "source": [
    "$$\n",
    "X = U^{-1} L^{-1} P^T B\n",
    "= (LU)^{-1} P^T B\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4638ba7",
   "metadata": {},
   "source": [
    "`lu_solve` takes $LU$, `pivots`, and $B$ as arguments and calculates the solution $X$ to the equation $X = (LU)^{-1} P^T B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b1d1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In PyTorch, the CPU impl of `lu_solve` just calls into the LAPACK function [`[s|d|z|c]getrs`](https://www.netlib.org/lapack/explore-html/df/d36/group__getrs.html). LAPACK is very difficult to understand in my opinion, and I won't attempt it. SciPy also just calls the LAPACK function. The CUDA impl in PyTorch uses either CuBLAS, MAGMA, or a custom implementation, depending on the situation. CuBLAS is closed source, so I cannot learn much about it. The MAGMA function is named [`magma_[s|d|z|c]getrs_batched`](https://icl.utk.edu/projectsfiles/magma/doxygen/group__magma__getrs__batched.html).\n",
    "\n",
    "The MAGMA implementation of `lu_solve` for complex numbers is essentially [this](https://github.com/icl-utk-edu/magma/blob/f360e055c1f54322807f5dcda75d41b2d6c1410a/src/zgetrs_gpu.cpp#L186-L216). The meat of it is a pair of calls to `magma_ztrs[v|m]`, which are triangular solve functions.\n",
    "\n",
    "The custom CUDA impl of `lu_solve` in PyTorch is [this](https://github.com/pytorch/pytorch/blob/8e8cbb85ee927776210f7872e3d0286d5d40dc14/aten/src/ATen/native/cuda/linalg/BatchLinearAlgebra.cpp#L2473-L2494), which is also a pair of triangular solve function calls.\n",
    "\n",
    "MLX also has a solver [here](https://github.com/ml-explore/mlx/blob/27778156dcbabbd7077985e8ea0683cf3ce04cfb/mlx/linalg.cpp#L680-L694), which accepts $A$ rather than $LU$ and `pivots`, but it decomposes $A$ into $LU$ and runs a pair of triangular solves.\n",
    "\n",
    "JAX also has an `lu_solve` function which is implemented [here](https://github.com/jax-ml/jax/blob/30582db24e8794abd09df2b3120aa5b58af8e9fe/jax/_src/lax/linalg.py#L1604-L1621) with a pair of triangular solve function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638efd4",
   "metadata": {},
   "source": [
    "So everywhere I look for open source implementations of `lu_solve`, I see a pair of triangular solves. PyTorch's `triangular_solve` function currently supports MPS inputs, so I should be able to mimic what all these these other `lu_solve` impls are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9122fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def my_pivots_to_permutation(pivots, size, *, inverse=False):\n",
    "    perm = torch.arange(size, dtype=torch.int32)\n",
    "    indices = range(size)\n",
    "    if inverse:\n",
    "        indices = reversed(indices)\n",
    "\n",
    "    for i in indices:\n",
    "        j = pivots[i] - 1\n",
    "        perm_i = perm[i].item()\n",
    "        perm_j = perm[j].item()\n",
    "        perm[i] = perm_j\n",
    "        perm[j] = perm_i\n",
    "\n",
    "    return perm\n",
    "\n",
    "def my_lu_solve(lu, pivots, b, trans):\n",
    "    m = lu.shape[0]\n",
    "    x = b\n",
    "\n",
    "    if trans == 0:\n",
    "        perm = my_pivots_to_permutation(pivots, m)\n",
    "        x = x[perm, :]\n",
    "        x = torch.linalg.solve_triangular(lu, x, left=True, upper=False, unitriangular=True)\n",
    "        x = torch.linalg.solve_triangular(lu, x, left=True, upper=True)\n",
    "\n",
    "    elif trans == 1 or trans == 2:\n",
    "        lu_ = lu.T\n",
    "        if trans == 2:\n",
    "            lu_ = lu_.conj()\n",
    "\n",
    "        x = torch.linalg.solve_triangular(lu_, x, left=True, upper=False)\n",
    "        x = torch.linalg.solve_triangular(lu_, x, left=True, upper=True, unitriangular=True)\n",
    "        inv_perm = my_pivots_to_permutation(pivots, m, inverse=True)\n",
    "        x = x[inv_perm, :]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14368c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=4 adjoint=False\n",
      "  OK\n",
      "m=5 adjoint=False\n",
      "  OK\n",
      "m=4 adjoint=True\n",
      "  OK\n",
      "m=5 adjoint=True\n",
      "  OK\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for adjoint, m in itertools.product([False, True], [4, 5]):\n",
    "    print(f'{m=} {adjoint=}')\n",
    "    for _ in range(100):\n",
    "        a = torch.randn(m, m, dtype=torch.cfloat)\n",
    "        b = torch.randn(m, m, dtype=torch.cfloat)\n",
    "        lu, pivots = torch.linalg.lu_factor(a)\n",
    "\n",
    "        r = my_lu_solve(lu, pivots, b, 2 if adjoint else 0)\n",
    "        r_check = torch.linalg.lu_solve(lu, pivots, b, adjoint=adjoint)\n",
    "        is_match = torch.allclose(r, r_check, atol=1e-4, rtol=1e-4)\n",
    "\n",
    "        if not is_match:\n",
    "            break\n",
    "\n",
    "    if not is_match:\n",
    "        print(\"  FAIL\")\n",
    "        print(f'{r=}')\n",
    "        print(f'{r_check=}')\n",
    "        raise RuntimeError(\"not a match\")\n",
    "    else:\n",
    "        print(\"  OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2439c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
