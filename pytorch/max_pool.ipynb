{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35203775",
   "metadata": {},
   "source": [
    "# Max pool\n",
    "\n",
    "Max pooling is an operation which does the following:\n",
    "\n",
    "* Split the input array elements into a number of equally sized groups, called \"pools\".\n",
    "* Find the maximum element in each pool.\n",
    "\n",
    "The pools are defined by a kernel size. The kernel function is just `max`. The kernel is swept over the array, non-overlapping, and it simply finds the maximum value of each pool.\n",
    "\n",
    "The basic cases are described by the equations in the pytorch docs: <https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f5e85",
   "metadata": {},
   "source": [
    "For example if we have the row-major 2x4 array:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "0 & 1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 & 7 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "With kernel size 2x1, we can only fit four kernels in the array, and we have four pools:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "0 \\\\\n",
    "4 \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "5 \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "2 \\\\\n",
    "6 \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "3 \\\\\n",
    "7 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The max value is chosen from each of the pools, and they are arranged in the same way the pools were arranged. So the result is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d8d8e",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "4 & 5 & 6 & 7 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985f452",
   "metadata": {},
   "source": [
    "There is also an optional parameter called dilation, which has a default of (1, 1), for 2d max pooling. Dilation tells us the stride over which the kernel spans. We essentially take a strided view of the input before applying the kernels.\n",
    "\n",
    "For instance, given the example array from above again, let's say we want to apply a 2x2 kernel with dilation $(1, 2)$.\n",
    "\n",
    "For the row dimension, we have 2 rows and kernel size of 2. The dilation of 1 means that the kernel looks at each successive row. So in the row dimension we can only fit the height of one kernel.\n",
    "\n",
    "Then for the column dimension, we have 4 columns and a kernel size of 2. But the dilation of 2 means that the kernel skips every second column. So we can only fit one kernel in this dimension as well. So we just have one pool:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ab76f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{pmatrix}\n",
    "0 & 2 \\\\\n",
    "4 & 6 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea07dd",
   "metadata": {},
   "source": [
    "The applying the max kernel to that, we get the final result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d02316",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "6 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596c4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586f30e",
   "metadata": {},
   "source": [
    "Here's a small Python impl of 2d max pooling, based off of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(\n",
    "    input,\n",
    "    kernel_size,\n",
    "    stride=None,\n",
    "    padding=0,\n",
    "    dilation=(1, 1),\n",
    "    #ceil_mode=False,\n",
    "    #return_indices=False,\n",
    "):\n",
    "    N, C, iH, iW = input.shape\n",
    "    kH, kW = kernel_size\n",
    "\n",
    "    if stride is None:\n",
    "        stride = kernel_size\n",
    "\n",
    "    sH, sW = stride\n",
    "\n",
    "    oH = (iH + 2 * padding - dilation[0] * (kernel_size[0] - 1) - 1) // stride[0] + 1\n",
    "    oW = (iW + 2 * padding - dilation[1] * (kernel_size[1] - 1) - 1) // stride[1] + 1\n",
    "\n",
    "    output = np.empty_like(input, shape=(N, C, oH, oW))\n",
    "\n",
    "    for h, w in itertools.product(range(oH), range(oW)):\n",
    "        output[:, :, h, w] = np.max(\n",
    "            input[\n",
    "                :, :,\n",
    "                (sH * h):(sH * h + kH * dilation[0]):dilation[0],\n",
    "                (sW * w):(sW * w + kW * dilation[1]):dilation[1],\n",
    "            ],\n",
    "            axis=(-2, -1))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af09ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2  3  4  5]\n",
      "   [ 6  7  8  9 10 11]\n",
      "   [12 13 14 15 16 17]\n",
      "   [18 19 20 21 22 23]\n",
      "   [24 25 26 27 28 29]\n",
      "   [30 31 32 33 34 35]]]]\n",
      "[[[[27 29]]]]\n",
      "[[[[27 29]]]]\n"
     ]
    }
   ],
   "source": [
    "a_shape = (1, 1, 6, 6)\n",
    "kernel_size = (3, 2)\n",
    "dilation = (2, 3)\n",
    "\n",
    "a = np.arange(np.prod(a_shape)).reshape(a_shape)\n",
    "b = max_pool2d(\n",
    "    a,\n",
    "    kernel_size,\n",
    "    dilation=dilation,\n",
    ")\n",
    "print(a)\n",
    "print(b)\n",
    "c = torch.nn.functional.max_pool2d(\n",
    "    torch.from_numpy(a),\n",
    "    kernel_size,\n",
    "    dilation=dilation,\n",
    ").numpy()\n",
    "print(c)\n",
    "assert np.allclose(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3a65d",
   "metadata": {},
   "source": [
    "The main problem with how the above is implemented is that if we have an array that is much larger than the kernel, then we're doing a lot of loop iterations. It would be nice to be able to parallelize all of the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31a238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 7.],\n",
      "         [2., 3.]]])\n",
      "tensor([[[ 1.,  7.,  4.],\n",
      "         [ 2.,  3., 11.],\n",
      "         [ 5., 12., -9.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "x = torch.tensor([\n",
    "    [-2, 1, 2,  6,  4],\n",
    "    [-3, 1, 7,  2, -2],\n",
    "    [-4, 2, 3, -1, -3],\n",
    "    [-7, 1, 2,  3, 11],\n",
    "    [5, -7, 8, 12, -9]\n",
    "]).float()\n",
    "x = x.unsqueeze(0)\n",
    "y_1 = nn.MaxPool2d(kernel_size=2,stride=2, padding=0)\n",
    "y_2 = nn.MaxPool2d(kernel_size=2,stride=2, padding=0, ceil_mode=True)\n",
    "print(y_1(x))\n",
    "print(y_2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7aee84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5, 7]]])\n",
      "tensor([[[0, 2, 3],\n",
      "         [4, 6, 7]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5, 6, 7],\n",
    "]])\n",
    "\n",
    "y_1 = nn.MaxPool2d(kernel_size=2, padding=0)\n",
    "y_2 = nn.MaxPool2d(kernel_size=2, padding=1)\n",
    "\n",
    "print(y_1(x))\n",
    "print(y_2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058885e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 1., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = torch.tensor([[\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5, 6, 7],\n",
    "]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "output = torch.nn.MaxPool2d(kernel_size=2)(input)\n",
    "\n",
    "output.backward(torch.ones_like(output))\n",
    "\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be685b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl-mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
