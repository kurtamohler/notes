{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_orig = torch.tensor([\n",
    "  [1], [2], [3], [4],\n",
    "  [2], [3], [4]\n",
    "])\n",
    "\n",
    "dim = -1\n",
    "\n",
    "reset = torch.tensor([\n",
    "  [True], [False], [False], [False],\n",
    "  [True], [False], [False]\n",
    "])\n",
    "\n",
    "data = torch.tensor([\n",
    "    [[0], [0], [0], [0], [0], [1]],\n",
    "    [[0], [0], [0], [0], [1], [2]],\n",
    "    [[0], [0], [0], [1], [2], [3]],\n",
    "    [[0], [0], [1], [2], [3], [4]],\n",
    "\n",
    "    [[0], [1], [2], [3], [4], [2]],\n",
    "    [[1], [2], [3], [4], [2], [3]],\n",
    "    [[2], [3], [4], [2], [3], [4]],\n",
    "])\n",
    "\n",
    "done_mask_expand = torch.tensor([\n",
    "    [True, True,  True,  True,  True, False],\n",
    "    [True, True,  True,  True, False, False],\n",
    "    [True, True,  True, False, False, False],\n",
    "    [True, True, False, False, False, False],\n",
    "\n",
    "    [True, True,  True,  True,  True, False],\n",
    "    [True, True,  True,  True, False, False],\n",
    "    [True, True,  True, False, False, False]\n",
    "])\n",
    "\n",
    "expected_res = torch.tensor([\n",
    "    [[1], [1], [1], [1], [1], [1]],\n",
    "    [[1], [1], [1], [1], [1], [2]],\n",
    "    [[1], [1], [1], [1], [2], [3]],\n",
    "    [[1], [1], [1], [2], [3], [4]],\n",
    "    [[2], [2], [2], [2], [2], [2]],\n",
    "    [[2], [2], [2], [2], [2], [3]],\n",
    "    [[2], [2], [2], [2], [3], [4]],\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 4, 3, 2, 5, 4, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = data.ndim + dim - 1\n",
    "n_feat = data.shape[data.ndim + dim :].numel()\n",
    "num_repeats_per_sample = done_mask_expand.flatten(d, -1).sum(-1).view(-1) // n_feat\n",
    "num_repeats_per_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1]), tensor([2])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_any = reset.any(-1, False)\n",
    "reset_vals = list(data_orig[reset_any].unbind(0))\n",
    "reset_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 4], [4, 7]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "j_ = float('inf')\n",
    "ranges = []\n",
    "range_start = 0\n",
    "\n",
    "for j in done_mask_expand.flatten(d, -1).sum(-1).view(-1) // n_feat:\n",
    "    if j > j_:\n",
    "        ranges.append([range_start, int(j)-1])\n",
    "        range_start = int(j)-1\n",
    "    j_ = j\n",
    "\n",
    "ranges.append([range_start, data.size(0)])\n",
    "\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1, 2],\n",
      "        [0, 0, 0, 1, 2, 3],\n",
      "        [0, 0, 1, 2, 3, 4]])\n",
      "tensor([5, 4, 3, 2])\n",
      "0 5 0\n",
      "1 4 0\n",
      "2 3 0\n",
      "3 2 0\n",
      "tensor([[0, 1, 2, 3, 4, 2],\n",
      "        [1, 2, 3, 4, 2, 3],\n",
      "        [2, 3, 4, 2, 3, 4]])\n",
      "tensor([5, 4, 3])\n",
      "0 5 1\n",
      "1 4 1\n",
      "2 3 1\n",
      "tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 2],\n",
      "        [1, 1, 1, 1, 2, 3],\n",
      "        [1, 1, 1, 2, 3, 4],\n",
      "        [2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2, 3],\n",
      "        [2, 2, 2, 2, 3, 4]])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "data_copy = data.clone()\n",
    "for range_num, (start, end) in enumerate(ranges):\n",
    "    data_slice = data_copy[start:end]\n",
    "    print(data_slice.squeeze(-1))\n",
    "    slices = []\n",
    "    print(num_repeats_per_sample[start:end])\n",
    "\n",
    "    for sample_idx, num_repeats in enumerate(num_repeats_per_sample[start:end]):\n",
    "        if num_repeats > 0:\n",
    "            print(f\"{sample_idx} {num_repeats} {range_num}\")\n",
    "            data_slice[sample_idx, :num_repeats] = reset_vals[range_num]\n",
    "\n",
    "print(data_copy.squeeze(-1))\n",
    "print((data_copy == expected_res).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repro from user\n",
    "\n",
    "A user reported this in Discord: <https://discord.com/channels/1171857748607115354/1268244652180377732/1270523213600002129>\n",
    "\n",
    "Here's the repro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT CATFRAMES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/endoplasm/develop/torchrl-0/torchrl/data/replay_buffers/samplers.py:1796: UserWarning: Left spanning is disabled for PrioritizedSliceSampler and will be automatically turned off. If this feature is required, please file an issue on torchrl GitHub repo.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchrl.envs import CatFrames, Compose\n",
    "from torchrl.data import PrioritizedSliceSampler, ReplayBuffer, LazyTensorStorage\n",
    "\n",
    "def catframes_speed_test(with_catframes=True):\n",
    "    from tensordict import TensorDict\n",
    "    import time\n",
    "\n",
    "    if with_catframes:\n",
    "        obs_shape = (16, 84, 84, 1)\n",
    "        transform = Compose(\n",
    "            CatFrames(N=4, dim=-1, in_keys=[\"observation\"], done_key=\"done\"),\n",
    "            CatFrames(N=4, dim=-1, in_keys=[(\"next\", \"observation\")], done_key=\"done\"))\n",
    "    else:\n",
    "        obs_shape = (16, 84, 84, 4)\n",
    "        transform = None\n",
    "\n",
    "    sampler = PrioritizedSliceSampler(\n",
    "        max_capacity=250_000,\n",
    "        alpha=0.5,\n",
    "        beta=0.4,\n",
    "        strict_length=False,\n",
    "        num_slices=32 // 4,\n",
    "        span=[True, False])\n",
    "\n",
    "    exp_buffer = ReplayBuffer(\n",
    "            storage=LazyTensorStorage(max_size=250_000, device=\"cpu\"),\n",
    "            sampler=sampler,\n",
    "            batch_size=32,\n",
    "            transform=transform\n",
    "        )\n",
    "    fake_data = TensorDict(\n",
    "        {\n",
    "            \"observation\": torch.zeros(obs_shape, dtype=torch.float32),\n",
    "            \"next\": {\"observation\": torch.zeros(obs_shape, dtype=torch.float32),\n",
    "                     \"done\": torch.zeros((obs_shape[0], 1), dtype=torch.bool)},\n",
    "        },\n",
    "        batch_size=[obs_shape[0]],\n",
    "    )\n",
    "\n",
    "    for _ in range(25):\n",
    "        exp_buffer.extend(fake_data)\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    data, info = exp_buffer.sample(return_info=True)\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"Sampling took {t2 - t1} seconds.\")\n",
    "\n",
    "    exp_buffer.empty()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"WITHOUT CATFRAMES\")\n",
    "    catframes_speed_test(with_catframes=False)\n",
    "\n",
    "    print(\"WITH CATFRAMES\")\n",
    "    catframes_speed_test(with_catframes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl-0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
