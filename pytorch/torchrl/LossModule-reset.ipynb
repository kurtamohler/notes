{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LossModule parameter reset\n",
    "\n",
    "Sometimes, it may be necessary to reset the trainable parameters of the functions that a `LossModule` is calculating a loss for.\n",
    "\n",
    "### Current behavior\n",
    "\n",
    "Currently, in order to reset the parameters, a user has directly access the child modules of the loss module. The child modules represet the trainable functions that the loss module calculates the loss for.\n",
    "\n",
    "For instance, in the following code, we are setting up a value function and loss for DQN, and then we reset the parameters on the value function directly by calling its `reset_parameters_recursive` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3242], grad_fn=<SelectBackward0>)\n",
      "tensor([0.8511], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.objectives import DQNLoss\n",
    "from torchrl.modules import QValueActor\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "module = nn.Sequential(nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "\n",
    "value_net = QValueActor(module=module, action_space=\"categorical\")\n",
    "loss = DQNLoss(value_network=value_net, action_space=\"categorical\")\n",
    "\n",
    "print(loss.value_network_params['module', '0', 'module', '0', 'weight'][0])\n",
    "\n",
    "value_net.reset_parameters_recursive()\n",
    "\n",
    "print(loss.value_network_params['module', '0', 'module', '0', 'weight'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But `LossModule` also has target params, and we may need to reset those too.\n",
    "\n",
    "In order to reset the target params, we can temporarily put them into the value network by calling `to_module`, and then call the value network's reset function. `to_module` returns a TensorDict that has a context manager which will put the original parameters back into the value network upon exitting the `with` context. The target params were updated in place, so the changes to them persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3242])\n",
      "tensor([-0.2589])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/endoplasm/develop/torchrl-1/torchrl/objectives/common.py:436: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(loss.target_value_network_params['module', '0', 'module', '0', 'weight'][0])\n",
    "\n",
    "with loss.target_value_network_params.to_module(value_net):\n",
    "    value_net.reset_parameters_recursive()\n",
    "\n",
    "print(loss.target_value_network_params['module', '0', 'module', '0', 'weight'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "The problem is that this is annoying. The code required to reset the parameters of a loss module is a bit verbose to write, and it will be different for each different type of `LossModule`, since the child modules will be called different things.\n",
    "\n",
    "It would be nice if we can have a simple `LossModule.reset_parameters` function.\n",
    "\n",
    "### Previous ideas\n",
    "\n",
    "One of the ideas from [this PR](https://github.com/pytorch/rl/pull/2017) was to have an API that requires the user to supply their own reset function. An example was this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0736], grad_fn=<SelectBackward0>)\n",
      "tensor([0.1608])\n"
     ]
    }
   ],
   "source": [
    "def reset_parameters(params):\n",
    "    \"\"\" User specified resetting function depending on their needs for initialization \"\"\"\n",
    "    if len(params.shape) > 1:\n",
    "        # weights\n",
    "        nn.init.xavier_uniform_(params)\n",
    "    elif len(params.shape) == 1:\n",
    "        # biases\n",
    "        nn.init.zeros_(params)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown parameter shape: {}\".format(params.shape))\n",
    "  \n",
    "with loss.value_network_params.to_module(loss.value_network):\n",
    "    loss.apply(lambda x: reset_parameters(x.data) if hasattr(x, \"data\") else None)\n",
    "\n",
    "print(loss.value_network_params['module', '0', 'module', '0', 'weight'][0])\n",
    "print(loss.target_value_network_params['module', '0', 'module', '0', 'weight'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does accomplish the goal, but the issue with that is that it would be hard to make this kind of reset function work generically, since the reset function you'd have to write is very module-specific.\n",
    "\n",
    "That PR also tried to add a `LossModule.reset_parameters` function which requires a user-defined function--not too different than calling `LossModule.apply` directly.\n",
    "\n",
    "Vincent says [here](https://github.com/pytorch/rl/pull/2017#issuecomment-2009336630):\n",
    "> The way I usually see this work is to use the module `reset_parameters` if there is one, which provides a better control over difference in initialization methods.\n",
    "\n",
    "(Note, I think he actually meant to say `reset_parameters_recursive`.)\n",
    "\n",
    "What he means is that `LossModule.reset_parameters` should call the `reset_parameters_recursive` function of all of its child modules.\n",
    "\n",
    "**The point is that we need the default behavior to be a simple method call with no args, not requiring the user to supply a reset func.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature requirements\n",
    "\n",
    "To summarize what I think are the requirements of this feature, I need to make a reset function for `LossModule` which accomplishes the following:\n",
    "\n",
    "* Update both value params and target params for all child modules.\n",
    "* Match each set of params with its corresponding child module of the `LossModule` and uses that child module's `reset_parameters_recursive` function.\n",
    "* (Lower priority) Allow the user to optionally provide their own reset function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, I question the necessity of that last point. It seems to me that if the user wants to have fine-grained control and write their own reset function, they could just as easily access the child modules of the `LossModule` directly, rather than have this weird API that expects a user defined function. It would be hard to make it apparent what exactly is going on inside that function, whereas if the user accesses the child modules directly to reset, then it's clear to anyone reading the code where exactly these parameters are coming from and what they represent. (Perhaps it would be a good idea to document how a user can reset the target parameters with the `to_module` context manager.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['value_network_params.module.0.module.0.weight',\n",
       " 'value_network_params.module.0.module.0.bias',\n",
       " 'value_network_params.module.0.module.2.weight',\n",
       " 'value_network_params.module.0.module.2.bias']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n for n, p in loss.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', '_parameters', '_buffers', '_non_persistent_buffers_set', '_backward_pre_hooks', '_backward_hooks', '_is_full_backward_hook', '_forward_hooks', '_forward_hooks_with_kwargs', '_forward_hooks_always_called', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_state_dict_hooks', '_state_dict_pre_hooks', '_load_state_dict_pre_hooks', '_load_state_dict_post_hooks', '_modules', '_cache', '_param_maps', '_value_estimator', '_has_update_associated', 'value_type', '_tensor_keys', '_in_keys', 'double_dqn', 'delay_value', 'value_network', 'value_network_in_keys', 'loss_function', 'action_space', 'reduction'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['value_network_params', 'target_value_network_params'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(loss._networks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(loss.__dict__['value_network'], nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss.__dict__.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "ret = getattr(loss, \"value_network_params1\", None)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['value_network.value_network_params.module.0.module.0.weight',\n",
       " 'value_network.value_network_params.module.0.module.0.bias',\n",
       " 'value_network.value_network_params.module.0.module.2.weight',\n",
       " 'value_network.value_network_params.module.0.module.2.bias']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for a, b in loss.named_parameters(prefix='value_network')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = loss.value_network_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        module: TensorDict(\n",
       "            fields={\n",
       "                0: TensorDict(\n",
       "                    fields={\n",
       "                        module: TensorDict(\n",
       "                            fields={\n",
       "                                0: TensorDict(\n",
       "                                    fields={\n",
       "                                        bias: Parameter(shape=torch.Size([64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                        weight: Parameter(shape=torch.Size([64, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                    batch_size=torch.Size([]),\n",
       "                                    device=None,\n",
       "                                    is_shared=False),\n",
       "                                2: TensorDict(\n",
       "                                    fields={\n",
       "                                        bias: Parameter(shape=torch.Size([64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                        weight: Parameter(shape=torch.Size([64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                    batch_size=torch.Size([]),\n",
       "                                    device=None,\n",
       "                                    is_shared=False)},\n",
       "                            batch_size=torch.Size([]),\n",
       "                            device=None,\n",
       "                            is_shared=False)},\n",
       "                    batch_size=torch.Size([]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td._param_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5856, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5856)\n",
      "tensor(-0.0158, grad_fn=<SelectBackward0>)\n",
      "tensor(-0.5987)\n"
     ]
    }
   ],
   "source": [
    "from torchrl.objectives import DQNLoss\n",
    "from torchrl.modules import QValueActor\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "module = nn.Sequential(nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, 64))\n",
    "\n",
    "value_net = QValueActor(module=module, action_space=\"categorical\")\n",
    "loss = DQNLoss(value_network=value_net, action_space=\"categorical\")\n",
    "\n",
    "\n",
    "print(loss.value_network_params['module', '0', 'module', '0', 'bias'][0])\n",
    "print(loss._modules.get('target_value_network_params')['module', '0', 'module', '0', 'bias'][0])\n",
    "\n",
    "loss.reset_parameters_recursive()\n",
    "\n",
    "print(loss.value_network_params['module', '0', 'module', '0', 'bias'][0])\n",
    "print(loss._modules.get('target_value_network_params')['module', '0', 'module', '0', 'bias'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = loss._modules.get('target_value_network_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDictParams(params=TensorDict(\n",
       "    fields={\n",
       "        module: TensorDict(\n",
       "            fields={\n",
       "                0: TensorDict(\n",
       "                    fields={\n",
       "                        module: TensorDict(\n",
       "                            fields={\n",
       "                                0: TensorDict(\n",
       "                                    fields={\n",
       "                                        bias: Tensor(shape=torch.Size([64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                        weight: Tensor(shape=torch.Size([64, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                    batch_size=torch.Size([]),\n",
       "                                    device=None,\n",
       "                                    is_shared=False),\n",
       "                                2: TensorDict(\n",
       "                                    fields={\n",
       "                                        bias: Tensor(shape=torch.Size([64]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                        weight: Tensor(shape=torch.Size([64, 64]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                    batch_size=torch.Size([]),\n",
       "                                    device=None,\n",
       "                                    is_shared=False)},\n",
       "                            batch_size=torch.Size([]),\n",
       "                            device=None,\n",
       "                            is_shared=False)},\n",
       "                    batch_size=torch.Size([]),\n",
       "                    device=None,\n",
       "                    is_shared=False)},\n",
       "            batch_size=torch.Size([]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
